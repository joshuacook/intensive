{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals:\n",
    "\n",
    "1. An intuition for how and why principal component analysis works\n",
    "2. The derivation from ~~first principles~~ using `numpy` of the math behind PCA\n",
    "4. Discuss the assumptions behind PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reference](https://arxiv.org/pdf/1404.1100.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is PCA\n",
    "\n",
    "- a simple, non-parametric method of extracting relevant information from confusing data sets\n",
    "- a method for reducing a complex data set to a lower dimension\n",
    "- a method for revealing hidden dynamics in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-parametric\n",
    "\n",
    "\n",
    "    this_pca = PCA(n_components=5)\n",
    "    other_pca =  PCA(n_components=10)\n",
    "\n",
    "    this_pca.fit(some_data)\n",
    "    other_pca.fit(some_data)\n",
    "    \n",
    "If we were to run this code, then the first five components of `other_pca` will be the same as the five components of `this_pca`. The model is non-parametric i.e there are no parameters to tune. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here is the perspective: we are an experimenter. We are trying to understand some phenomenon by measuring various quantities (e.g. spectra, voltages, velocities, etc.) in our system. Unfortunately, we can not figure out what is happening because the data appears clouded, unclear and even redundant. This is not a trivial problem, but rather a fundamental obstacle in empirical science. Examples abound from complex systems such as neuroscience, web indexing, meteorology and oceanography - the number of variables to measure can be unwieldy and at times even deceptive, because the underlying relationships can often be quite simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Toy Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretend we are studying the motion of the physicist’s ideal spring. \n",
    "\n",
    "This system consists of a ball of mass $m$ attached to a massless, frictionless spring. \n",
    "\n",
    "The ball is released a small distance away from equilibrium (i.e. the spring is stretched). \n",
    "\n",
    "Because the spring is ideal, it oscillates indefinitely along the $x$-axis about its equilibrium at a set frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.evernote.com/l/AAFyWbRBljJIqqUfNcOo8SvvvPa3gCnvCsAB/image.png\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being ignorant experimenters we do not know any of this. \n",
    "\n",
    "We do not know which, let alone how many, axes and dimensions are important to measure. \n",
    "\n",
    "Unfortunately, because of our ignorance, we do not even know what are the real axes, so we choose three camera positions $\\mathbf{a}$, $\\mathbf{b}$ and $\\mathbf{c}$ at some arbitrary angles with respect to the system. \n",
    "\n",
    "The angles between our measurements might not even be 90$^\\circ$! \n",
    "\n",
    "Now, we record with the cameras for several minutes - an $x$ and $y$ value for the ball at each moment in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_pickle('../data/ball_on_spring.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these diagrams, the green arrow represents the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(15,4))\n",
    "for i, cam in enumerate(['a', 'b', 'c']):\n",
    "    x_axis = 'x_{}'.format(cam)\n",
    "    y_axis = 'y_{}'.format(cam)\n",
    "    data_df.plot(x_axis, y_axis, kind='scatter', ax=ax[i], xlim=(-4,4), ylim=(-4,4))\n",
    "    ax[i].axvline(c='black')\n",
    "    ax[i].axhline(c='black')\n",
    "    ax[i].arrow(0,-4,0,1,color='green',lw=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we get from this data set to a simple equation of $x$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We know a-priori that if we were smart experimenters, we would have just measured the position along the x-axis with one camera. But this is not what happens in the real world. We often do not know which measurements best reflect the dynamics of our system in question. Furthermore, we sometimes record more dimensions than we actually need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Change of Basis\n",
    "\n",
    "\n",
    "The goal of principal component analysis is to identify the most meaningful basis to re-express a data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example of the spring, the explicit goal of PCA is to determine: \n",
    "\n",
    "> “the dynamics are along the $x$-axis.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance and the Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a high-level, our goal is to find a transformation for our data so that it is a \"best expression\" of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, this looks like this \n",
    "\n",
    "$$X' = PX$$\n",
    "\n",
    "where $X$ is the original data and $X'$ is the transformed, \"best expression\" of the data. \n",
    "\n",
    "$P$ is a permutation or transformation matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Transformation: Rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example of a transformation is a rotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_A_df = data_df[['x_a', 'y_a']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_rotation(dataframe, angle):\n",
    "    angle = np.pi/180*angle\n",
    "    tmp_df = dataframe.copy()\n",
    "    tmp_df.columns = ['x', 'y']\n",
    "    tmp_df['x'] = np.cos(angle)*tmp_df['x']\n",
    "    tmp_df['y'] = np.sin(angle)*tmp_df['y']\n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measured Camera A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.scatter(cam_A_df.x_a, cam_A_df.y_a)\n",
    "plt.xlim(-3,3)\n",
    "plt.ylim(-3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Camera A Rotated 85°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4))\n",
    "cam_A_rot = pd_rotation(cam_A_df, 85)\n",
    "plt.scatter(cam_A_rot.x, cam_A_rot.y)\n",
    "plt.xlim(-3,3)\n",
    "plt.ylim(-3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Camera A Rotated -65°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4))\n",
    "cam_A_rot = pd_rotation(cam_A_df, -65)\n",
    "plt.scatter(cam_A_rot.x, cam_A_rot.y)\n",
    "plt.xlim(-3,3)\n",
    "plt.ylim(-3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The $P$ we seek will transform $X$ so that $X'$ has minimal confounding data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinds of Confounding Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are essentially two kinds of confounding data that we need to minimize:\n",
    "\n",
    "- noise\n",
    "- redundancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Noise in any data set must be low or - no matter the analysis technique - no information about a system can be extracted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise\n",
    "\n",
    "We previously considered noise in looking at the expresion of a linear model.\n",
    "\n",
    "$$f(x) = \\beta_0 + \\beta_1x + \\epsilon$$\n",
    "\n",
    "Here, $\\epsilon$ represents noise inherent to the model.\n",
    "\n",
    "As outlined in the Data Generation Notebook, there are two sources of noise:\n",
    "\n",
    "1. the actual motion of the mass is imperfect\n",
    "2. the equipment is not perfect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's consider noise by looking at the data collected by individual cameras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(15,4))\n",
    "for i, cam in enumerate(['a', 'b', 'c']):\n",
    "    x_axis = 'x_{}'.format(cam)\n",
    "    y_axis = 'y_{}'.format(cam)\n",
    "    sns.regplot(x_axis, y_axis, data=data_df, ax=ax[i])\n",
    "    ax[i].axvline(c='black')\n",
    "    ax[i].axhline(c='black')\n",
    "    ax[i].set_ylim(-2.2,2.2)\n",
    "    ax[i].set_xlim(-2.2,2.2)\n",
    "    ax[i].arrow(0,-2.2,0,.3,color='green',lw=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have used `sns.regplot` to plot the scatter plot of each $x,y$ pair along with a linear regression fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line of Best Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also compute this line if we so desired. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(cam_A_df[['x_a']], cam_A_df[['y_a']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_, lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_A_line_best_fit = lambda x: lr.intercept_ + lr.coef_*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = cam_A_df.x_a.values\n",
    "yy = cam_A_df.y_a.values\n",
    "plt.scatter(xx, yy, label = 'actual')\n",
    "plt.scatter(xx, cam_A_line_best_fit(xx), label = 'line of best fit')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the level of noise by looking at the signal to noise ratio\n",
    "\n",
    "$$SNR = \\frac{\\sigma^2_{signal}}{\\sigma^2_{noise}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we will need to calculate the variance for the signal and the variance for the noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.evernote.com/l/AAEGF_wOI_9AUJUqHm7JOlm75jBG5hQR_uYB/image.png\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the mass on the spring travels in a single dimension. This dimension is the line of best fit of our data. Any deviation from this is noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the variance for the given features using `pd.DataFrame.cov()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_A = data_df[['x_a','y_a']]\n",
    "cam_B = data_df[['x_b','y_b']]\n",
    "cam_C = data_df[['x_c','y_c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding covariances for each camera along the camera's axes\n",
    "\n",
    "cam_A_cov = cam_A.cov()\n",
    "cam_B_cov = cam_B.cov()\n",
    "cam_C_cov = cam_C.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cam_A_cov)\n",
    "display(cam_B_cov)\n",
    "display(cam_C_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These represent the variance along the axes defined by each camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_w_x_y_var(cam, ax):\n",
    "    x_axis = 'x_{}'.format(cam)\n",
    "    y_axis = 'y_{}'.format(cam)\n",
    "\n",
    "    sns.regplot(x_axis, y_axis, data=data_df, ax=ax)\n",
    "    x_a_var =  data_df[x_axis].values.var()\n",
    "    x_a_mean = data_df[x_axis].values.mean()\n",
    "    y_a_var =  data_df[y_axis].values.var()\n",
    "    y_a_mean = data_df[y_axis].values.mean()\n",
    "    \n",
    "    # plotting the vector origin on the mean, it's starting from the data's mean and plotting variance fr: there \n",
    "    ax.arrow(x_a_mean,y_a_mean,x_a_var, 0, lw=5)\n",
    "    ax.arrow(x_a_mean,y_a_mean,0,y_a_var, lw=5)\n",
    "\n",
    "    ax.axvline(c='black')\n",
    "    ax.axhline(c='black')\n",
    "    ax.set_ylim(-3,3)\n",
    "    ax.set_xlim(-3,3)\n",
    "    ax.arrow(0,-2.2,0,.3,color='green',lw=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(15,4))\n",
    "for i, cam in enumerate(['a', 'b', 'c']):\n",
    "    plot_w_x_y_var(cam, ax[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigendecomposition\n",
    "\n",
    "We can find the variance of the signal and the noise by doing an eigendecomposition on the covariance matrix.\n",
    "\n",
    "$$X_{cov} = V\\Lambda V^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals_A, eig_vecs_A = np.linalg.eig(cam_A_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eig_vals_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vecs_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "some_vector = [1,2,3,4,5]\n",
    "np.diag(some_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Take the eigenvalues and convert it to a Lambda matrix with just eigenvalues as the diags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eigen values are the variances \n",
    "#eigen vectors are the direction of the variance\n",
    "\n",
    "V = eig_vecs\n",
    "Lambda = np.diag(eig_vals)\n",
    "Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_A_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(V.dot(Lambda).dot(V.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_with_eigenvecs(cam, dataframe, evals, evecs):\n",
    "    x_axis = 'x_{}'.format(cam)\n",
    "    y_axis = 'y_{}'.format(cam)\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    sns.regplot(x_axis, y_axis, dataframe)\n",
    "    \n",
    "    plt.ylim(-3,3)\n",
    "    plt.xlim(-3,3)\n",
    "    \n",
    "    plt.axvline(c='black')\n",
    "    plt.axhline(c='black')\n",
    "    \n",
    "    mean = dataframe[[x_axis, y_axis]].mean()\n",
    "    \n",
    "    var_1 = evals[0]*evecs[:,0]\n",
    "    var_2 = evals[1]*evecs[:,1]\n",
    "    \n",
    "    plt.arrow(mean[0],mean[1],*var_1, lw=5)\n",
    "    plt.arrow(mean[0],mean[1],*var_2, lw=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals_A, eig_vecs_A = np.linalg.eig(cam_A_cov)\n",
    "plot_data_with_eigenvecs('a', data_df, eig_vals_A, eig_vecs_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals_B, eig_vecs_B = np.linalg.eig(cam_B_cov)\n",
    "plot_data_with_eigenvecs('b', data_df, eig_vals_B, eig_vecs_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals_C, eig_vecs_C = np.linalg.eig(cam_C_cov)\n",
    "plot_data_with_eigenvecs('c', data_df, eig_vals_C, eig_vecs_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera A signal-to-noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_to_noise(var_signal, var_noise):\n",
    "    return var_signal/var_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_to_noise(eig_vals_A[0], eig_vals_A[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera B signal-to-noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eig_vals_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_to_noise(eig_vals_B[0], eig_vals_B[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera C signal-to-noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_to_noise(eig_vals_C[1], eig_vals_C[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These calculations give us some understanding of the noise introduced by our collection tools -- the cameras.\n",
    "\n",
    "Recall that when we created the data, we had \n",
    "\n",
    "    noise_factor_A = .4\n",
    "    noise_factor_B = 1.1\n",
    "    noise_factor_C = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Does this make sense with the signal-to-noise ratios we calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redundancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.evernote.com/l/AAFmvCethNZME6R1UZOilfN2DuJPpzDuoTsB/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redundancy is a bit trickier. There are certainly two kinds of redundancy here.\n",
    "\n",
    "- three cameras capture the exact same phenomenon\n",
    "- each camera captures two dimensions of data, where a single variable will do\n",
    "\n",
    "In panel (c) above, it would be more meaningful to just have recorded a single variable, the linear combination $r_2 − kr_1$, instead of two variables $r_1$ and $r_2$ separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the idea behind dimensional reduction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
